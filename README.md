ğŸ“š Web-Digest-AI

AI-powered website summarization using LLMs

Web-Digest-AI extracts content from a webpage and produces high-quality summaries using a Large Language Model (LLM).


ğŸš€ Features

ğŸŒ Extract content from any public website

ğŸ“„ Summarize long web pages using LLMs


ğŸ“‚ Project Structure
web-digest-ai/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ web_digest_ai.ipynb
â”‚
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
âš™ï¸ How It Works
Step 1 â€” Web Scraping

Extract raw HTML content from a URL and clean it.

Step 2 â€” LLM Summarization

Send processed content to LLM to generate final summary.

â–¶ï¸ Installation
1ï¸âƒ£ Clone Repository
git clone https://github.com/varalakshmi-iyer/web-digest-ai.git
cd web-digest-ai
2ï¸âƒ£ Install Dependencies
uv sync

3ï¸âƒ£ Set Environment Variables

Create a .env file:

OPENAI_API_KEY=your_api_key_here

Load it in notebook:

from dotenv import load_dotenv
import os

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
4ï¸âƒ£ Run Notebook
jupyter notebook

Open:

notebooks/web_digest_ai.ipynb

ğŸ§‘â€ğŸ’» Author
GitHub: https://github.com/varalakshmi-iyer/